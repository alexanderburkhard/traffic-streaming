services:
  broker-1:
    image: apache/kafka:latest
    hostname: broker-1
    container_name: broker-1
    ports:
      - 9092:9092
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_BROKER_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://broker-1:9092,CONTROLLER://broker-1:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-1:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker-1:9093
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs

  # spark:
  #   build: 
  #     context: ./data-processor
  #     dockerfile: ./Dockerfile
  #   environment:
  #     - SPARK_MASTER=spark://spark:7077
  #     - SPARK_LOCAL_IP=spark
  #   ports:
  #     - "4040:4040"

  quix-processor:
    build:
      context: ./quix-processor
      dockerfile: ./Dockerfile
    container_name: quix-processor
    depends_on:
      - broker-1
    environment:
      - KAFKA_BROKER=broker-1:9092
    command: python main.py

  data-producer:
    build: 
      context: ./data-producer
      dockerfile: ./Dockerfile
    container_name: data-producer
    depends_on:
       - broker-1
       - quix-processor
       - postgresql
    volumes:
      - ./data-producer/csv_files:/csv_files

  postgresql:
    image: postgres:15
    container_name: postgres_db
    restart: always
    environment:
      POSTGRES_USER: sparkuser
      POSTGRES_PASSWORD: sparkpass
      POSTGRES_DB: traffic_db
    ports:
      - "5432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./postgresql:/docker-entrypoint-initdb.d/ # every .sql file in this folder gets executed upon start

volumes:
  pg_data:
